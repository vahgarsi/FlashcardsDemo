# Show where LLM fails (wrong pairs). Show where the image generation model fails (busy images, non-focal objects). 

## Limitations of Large Language Models (LLMs):

1. Lack of Factual Accuracy: LLMs can generate text based on patterns learned from the training data, but they may not always produce accurate information. They can generate plausible-sounding sentences that are factually incorrect or misleading.

Example: A model might generate a statement like, "The Eiffel Tower is located in London," which is factually incorrect.

2. Bias and Sensitivity to Input Phrasing: LLMs can inadvertently produce biased or politically sensitive responses, as they learn from data on the internet that contains biases. Their responses can be influenced by the phrasing of the input.

Example: A model might respond differently to "Are men better at math?" compared to "Are women worse at math?" even though both questions are framed similarly.

3. Generating Inappropriate Content: LLMs can sometimes generate content that is offensive, inappropriate, or harmful, especially if prompted with inappropriate inputs.

Example: Some users have found that LLMs can generate offensive or discriminatory language when given certain prompts.

4. Difficulty in Handling Ambiguity: LLMs may struggle with understanding and resolving ambiguous language, leading to responses that are contextually incorrect or unclear.

Example: If asked, "I saw a man with a telescope," the model might not discern whether the person was using the telescope or if the man himself had one.

## Limitations of Image Generation Models:

1. Busy Images: Image generation models can have difficulty generating clear and coherent images when presented with complex scenes or busy backgrounds. They may produce images with cluttered or unclear elements.

Example: When asked to generate an image of a crowded city street, the model might create an image that lacks clear focus or is overly cluttered.

2. Non-Focal Objects: Image generation models may not always correctly identify and emphasize the most important or focal objects in a scene. This can result in images where the main subject is not appropriately highlighted.

Example: If asked to generate an image of a person holding a book, the model might place too much emphasis on the background or other objects, making the person and the book less prominent.

3. Limited Realism: While image generation models have improved significantly, they may still generate images that lack the realism of photographs. Generated images may appear stylized or abstract.

Example: Images generated by the model might have an artistic or painterly quality rather than looking like traditional photographs.

4. Artifact Generation: Image generation models can sometimes produce artifacts or inconsistencies in images, such as unrealistic lighting, strange colors, or distortions.

Example: Generated images may contain unnatural color gradients or lighting effects that are not seen in real-world photographs.
